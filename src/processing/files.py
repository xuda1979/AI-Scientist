"""
File management and project setup utilities.
"""
from __future__ import annotations
import logging
import shutil
import hashlib
from textwrap import dedent
from typing import Tuple, Optional
from pathlib import Path


logger = logging.getLogger(__name__)


DEFAULT_PAPER_TEMPLATE = dedent(r"""
% AI Scientist default research paper scaffold
\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, graphicx, booktabs}
\usepackage[hidelinks]{hyperref}
\usepackage{microtype}
\title{Research Title Placeholder}
\author{AI Scientist Workflow}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
% TODO: Summarize the core contribution and key results in 150 words or fewer.
\end{abstract}

\section{Introduction}
% Describe the problem context, articulate the core research question, and motivate why it matters now.

\section{Related Work}
% Cite the most relevant literature and identify concrete gaps that the paper addresses.

\section{Methodology}
% Detail the proposed approach with equations or algorithms so the method is reproducible.

\section{Experiments}
% Describe datasets, baselines, metrics, and experimental protocol. Include ablations if applicable.

\section{Results and Discussion}
% Present quantitative/qualitative findings and interpret what they mean for the research question.

\section{Conclusion}
% Summarize the takeaways, limitations, and future work opportunities.

\bibliographystyle{ieeetr}
\bibliography{references}
\end{document}
""").strip() + "\n"


DEFAULT_SIMULATION_TEMPLATE = dedent(
    """\
\"\"\"Experiment scaffold generated by AI Scientist.\"\"\"

from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict


def load_experiment_config(config_path: Path | str = "config.json") -> Dict[str, Any]:
    \"\"\"Load experiment configuration if it exists.\"\"\"
    path = Path(config_path)
    if not path.exists():
        return {}
    with path.open("r", encoding="utf-8") as handle:
        return json.load(handle)


def run_experiments() -> Dict[str, Any]:
    \"\"\"Implement the core simulation or evaluation loop.\"\"\"
    config = load_experiment_config()
    # TODO: Replace placeholder logic with the actual experimental workflow.
    metrics = {
        "status": "placeholder",
        "notes": "Populate this with real experiment results",
    }
    return metrics


def save_results(results: Dict[str, Any], output_path: Path | str = "results.json") -> None:
    \"\"\"Persist results so they can be referenced by the paper.\"\"\"
    path = Path(output_path)
    path.write_text(json.dumps(results, indent=2), encoding="utf-8")


if __name__ == "__main__":
    experiment_results = run_experiments()
    save_results(experiment_results)
    print("No simulation code found yet â€” populated default scaffold.")
"""
).strip() + "\n"


# Compatibility function to replace utils.sim_runner.ensure_single_tex_py
def ensure_single_tex_py(project_dir: Path, strict: bool = True, preserve_original_filename: bool = False) -> Tuple[Path, Path]:
    """Compatibility wrapper for ensure_single_tex_file."""
    file_manager = FileManager()
    return file_manager.ensure_single_tex_file(project_dir, strict, preserve_original_filename)


class FileManager:
    """Handle file operations and project setup."""
    
    def __init__(self):
        self.file_hashes = {}
    
    def prepare_project_directory(self, output_dir: Path, modify_existing: bool = False) -> Path:
        """Prepare project directory for workflow."""
        if modify_existing and output_dir.exists():
            logger.info("Using existing project directory: %s", output_dir)
            return output_dir
        
        # Create new project directory
        if output_dir.exists() and not modify_existing:
            # Create unique directory name
            counter = 1
            base_name = output_dir.name
            while output_dir.exists():
                output_dir = output_dir.parent / f"{base_name}_{counter}"
                counter += 1
        
        output_dir.mkdir(parents=True, exist_ok=True)
        logger.info("Created project directory: %s", output_dir)
        
        return output_dir
    
    def ensure_single_tex_file(
        self, 
        project_dir: Path, 
        strict: bool = True,
        preserve_original_filename: bool = False
    ) -> Tuple[Path, Path]:
        """Ensure exactly one .tex file and one .py file exist."""
        tex_files = list(project_dir.glob("*.tex"))
        py_files = list(project_dir.glob("*.py"))
        
        # Handle .tex files
        if len(tex_files) == 0:
            # Create a rich default scaffold to guide high-quality papers
            paper_path = project_dir / "paper.tex"
            paper_path.write_text(DEFAULT_PAPER_TEMPLATE, encoding="utf-8")
        elif len(tex_files) == 1:
            paper_path = tex_files[0]
            # Rename to paper.tex if needed (unless preserving original filename)
            if not preserve_original_filename and paper_path.name != "paper.tex":
                new_path = project_dir / "paper.tex"
                paper_path.rename(new_path)
                paper_path = new_path
        else:
            if strict:
                raise ValueError(f"Multiple .tex files found: {[f.name for f in tex_files]}")
            # Use the largest file
            paper_path = max(tex_files, key=lambda f: f.stat().st_size)
            # Remove others
            for f in tex_files:
                if f != paper_path:
                    f.unlink()
        
        # Handle .py files  
        if len(py_files) == 0:
            # Create simulation scaffold to encourage reproducible experiments
            sim_path = project_dir / "simulation.py"
            sim_path.write_text(DEFAULT_SIMULATION_TEMPLATE, encoding="utf-8")
        elif len(py_files) == 1:
            sim_path = py_files[0]
            # Rename to simulation.py if needed (unless preserving original filename)
            if (
                not preserve_original_filename
                and sim_path.name != "simulation.py"
            ):
                new_path = project_dir / "simulation.py"
                sim_path.rename(new_path)
                sim_path = new_path
        else:
            if strict:
                raise ValueError(f"Multiple .py files found: {[f.name for f in py_files]}")
            # Use the largest file
            sim_path = max(py_files, key=lambda f: f.stat().st_size)
            # Remove others
            for f in py_files:
                if f != sim_path:
                    f.unlink()
        
        return paper_path, sim_path
    
    def check_file_changed(self, file_path: Path) -> bool:
        """Check if file has changed since last check."""
        if not file_path.exists():
            return False
        
        content = file_path.read_text(encoding="utf-8", errors="ignore")
        current_hash = hashlib.md5(content.encode()).hexdigest()
        
        file_key = str(file_path)
        if file_key not in self.file_hashes:
            self.file_hashes[file_key] = current_hash
            return True
        
        if self.file_hashes[file_key] != current_hash:
            self.file_hashes[file_key] = current_hash
            return True
        
        return False
    
    def backup_file(self, file_path: Path, backup_suffix: str = ".bak") -> Path:
        """Create backup of file."""
        backup_path = file_path.with_suffix(file_path.suffix + backup_suffix)
        shutil.copy2(file_path, backup_path)
        return backup_path
    
    def save_iteration_diff(
        self, 
        original_content: str, 
        new_content: str, 
        project_dir: Path, 
        iteration: int,
        filename: str = "paper.tex"
    ) -> None:
        """Save diff between iterations."""
        import difflib
        
        diff_dir = project_dir / "diffs"
        diff_dir.mkdir(exist_ok=True)
        
        # Generate unified diff
        diff = difflib.unified_diff(
            original_content.splitlines(keepends=True),
            new_content.splitlines(keepends=True),
            fromfile=f"{filename} (iteration {iteration-1})",
            tofile=f"{filename} (iteration {iteration})",
            lineterm=""
        )
        
        diff_path = diff_dir / f"iteration_{iteration}_{filename}.diff"
        with open(diff_path, 'w', encoding='utf-8') as f:
            f.writelines(diff)
        
        logger.info("Diff saved: %s", diff_path.name)
    
    def cleanup_temp_files(self, project_dir: Path) -> None:
        """Clean up temporary files."""
        temp_patterns = ["*.aux", "*.log", "*.out", "*.toc", "*.bbl", "*.blg", "*.fls", "*.fdb_latexmk"]
        
        for pattern in temp_patterns:
            for temp_file in project_dir.glob(pattern):
                try:
                    temp_file.unlink()
                except Exception:
                    pass  # Ignore cleanup errors
    
    def get_file_stats(self, project_dir: Path) -> dict:
        """Get statistics about project files."""
        stats = {
            "tex_files": len(list(project_dir.glob("*.tex"))),
            "py_files": len(list(project_dir.glob("*.py"))),
            "pdf_files": len(list(project_dir.glob("*.pdf"))),
            "total_files": len(list(project_dir.glob("*"))),
            "project_size_mb": sum(f.stat().st_size for f in project_dir.rglob("*") if f.is_file()) / 1024 / 1024
        }
        return stats
