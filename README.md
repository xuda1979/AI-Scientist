# AI-Scientist

_Automated research partner for planning studies, running simulations, and writing polished LaTeX papers._

## What is AI-Scientist?
AI-Scientist is an end-to-end workflow that helps you go from a research idea to a complete, publication-style paper. It blends large language models with programmatic checks so that every generated manuscript includes real references, self-contained figures, simulation code, and iterative peer review feedback. The goal is to let researchers, engineers, and curious builders focus on ideas while the workflow handles the repetitive writing and validation steps.

## What you get out of the box
- **Brainstorming & planning** – generates research directions, outlines, and section plans tailored to your topic.
- **Draft writing in LaTeX** – produces a single `paper.tex` that compiles on its own, with embedded references and figures.
- **Executable simulations** – extracts code from the paper, fixes issues, and runs it to produce real data for tables and plots.
- **Quality control** – scores every draft, runs structured reviews, validates DOIs, and checks that referenced figures actually exist.
- **Revision loop** – reviewer and author personas iterate until the manuscript meets configurable quality thresholds.
- **Detailed logs & artifacts** – stores intermediate outputs, simulation results, and decision logs so you can inspect every step.

## How the workflow runs (high-level)
1. **Collect inputs** – you provide a topic, field, and research question plus any custom instructions.
2. **Ideate** – the system brainstorms project ideas and selects the best candidate to pursue.
3. **Draft** – it writes `paper.tex` and accompanying `simulation.py`, ensuring figures/tables are generated by the simulation.
4. **Execute simulations** – extracted code is executed, and results are summarized for later use.
5. **Review & score** – automated reviewers evaluate structure, citations, visuals, and technical soundness.
6. **Revise** – revisions are applied until the editor approves and the quality score clears your threshold.
7. **Deliver** – the finished paper, simulation outputs, and logs are saved under `output/<project_name>/`.

## Getting started
### Prerequisites
- Python 3.10+ and `pip`.
- Access to at least one large language model. By default the workflow expects OpenAI GPT models; you can also configure an OSS 120B endpoint or Google Gemini.
- (Optional) Google Gemini API credentials if you plan to call Gemini models.

### Installation
```bash
git clone https://github.com/AI-Scientist/AI-Scientist.git
cd AI-Scientist
python -m venv .venv
source .venv/bin/activate  # On Windows use: .venv\Scripts\activate
pip install -r requirements.txt
```

### Configure model access
There are two common ways to provide credentials and settings:

1. **Environment variables** – export keys before running the workflow (for example `export OPENAI_API_KEY=...`). The CLI will
   emit a warning and temporarily use the value if it detects the common typo `OPEANAI_API_KEY`, but you should still rename the
   variable for future runs.
2. **Configuration file** – copy `config_example.json` to `config.json`, fill in keys such as `default_model`, `oss120b_api_key`, or `google_api_key`, and pass it with `--config config.json`.

Key fields you may want to update:
- `default_model`, `review_model`, `revision_model`, `brainstorm_model`
- `quality_threshold`, `max_iterations`
- `oss120b_endpoint` and `oss120b_api_key` if you host your own model server
- `google_api_key` and `google_api_proxy` (see [Google Gemini Configuration](#google-gemini-configuration))

### Run your first project
```bash
python sciresearch_workflow.py \
  --topic "Quantum-resistant encryption" \
  --field "Cryptography" \
  --question "How can lattice methods improve post-quantum key exchange?"
```

### Try the offline demo
If you do not have API keys handy, you can still see the orchestration in action by invoking the new offline mode. It spins up a
toy simulation, runs it locally, and assembles a reproducible paper bundle without calling external services.

```bash
python sciresearch_workflow.py \
  --topic "Autonomous alignment curricula" \
  --field "AI Safety" \
  --question "How can curriculum learning improve alignment heuristics?" \
  --offline-demo
```

The offline run produces a timestamped folder under `output/` containing `paper.tex`, `simulation.py`, the simulation outputs, and
an ideation summary that documents the generated experiment.

The command creates a timestamped folder inside `output/` containing:
- `paper.tex` – the LaTeX manuscript
- `simulation.py` – runnable code used to generate figures/tables
- `simulation_outputs/` – raw data and plots
- `logs/` – JSON summaries, review comments, and quality metrics

### Helpful command-line options
- `--user-prompt "..."` – inject custom instructions that take priority over defaults.
- `--quality-threshold 0.9` – raise or lower the acceptance bar.
- `--skip-reference-check` / `--skip-figure-validation` – disable intensive validation during experimentation.
- `--modify-existing` – ask the workflow to revise an existing `output/<name>/` directory.
- `--save-config config.json` – persist the active configuration for future runs.

For a deeper dive into features and prompts, see the documents in [`docs/`](docs/).

## Google Gemini Configuration
The workflow can call Google Gemini models via the Google AI SDK. To enable these calls:

1. Obtain an API key from the [Google AI Studio](https://ai.google.dev/).
2. Provide the key to the workflow using one of the following options:
   - Set the `GOOGLE_API_KEY` (or `GEMINI_API_KEY`) environment variable before running the workflow.
   - Add a `google_api_key` entry to your workflow configuration JSON (see `config_example.json`).
3. If your environment requires a proxy for outbound HTTPS traffic, set it with the `GOOGLE_API_PROXY` environment variable or the `google_api_proxy` configuration field.

When a Gemini model is selected without a configured API key, the workflow raises a clear error explaining how to supply the key.

## Project structure overview
```
AI-Scientist/
├─ sciresearch_workflow.py      # Main orchestration script
├─ utils/                       # Simulation runners, LaTeX helpers, validation tools
├─ src/                         # Supporting modules for the research workflow
├─ docs/                        # Detailed design notes and feature documentation
├─ output/                      # Created at runtime with paper-specific artifacts
└─ logs/                        # Centralized workflow logs (auto-created)
```

## Contributing & support
Issues and pull requests are welcome! If you run into problems, please open an issue with details about your configuration and logs. For feature requests or questions, feel free to start a discussion thread.

## Citation
If you use AI-Scientist in your research, please cite this software as follows:

```
@software{ai_scientist,
  author = {AI-Scientist Developers},
  title = {AI-Scientist},
  year = {2025},
  url = {https://github.com/AI-Scientist/AI-Scientist}
}
```

Please replace the URL or version number with the appropriate release or commit hash you used in your work.
