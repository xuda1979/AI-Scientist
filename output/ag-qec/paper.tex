\begin{filecontents*}{refs.bib}
@article{Poletti2014OPEX,
  author    = {Francesco Poletti},
  title     = {Nested antiresonant nodeless hollow core fiber},
  journal   = {Optics Express},
  year      = {2014},
  volume    = {22},
  number    = {20},
  pages     = {23807--23828},
  doi       = {10.1364/OE.22.023807}
}

@article{Benabid2006JLT,
  author    = {F. Benabid},
  title     = {Hollow-Core Photonic Crystal Fiber: A New Light Guide},
  journal   = {Journal of Lightwave Technology},
  year      = {2006},
  volume    = {24},
  number    = {12},
  pages     = {4624--4633},
  doi       = {10.1109/JLT.2006.885257}
}

@article{Eraerds2010NJP,
  author    = {P. Eraerds and N. Walenta and M. Legr{\'e} and N. Gisin and H. Zbinden},
  title     = {Quantum key distribution and 1 Gbps data encryption over a single fibre},
  journal   = {New Journal of Physics},
  year      = {2010},
  volume    = {12},
  pages     = {063027},
  doi       = {10.1088/1367-2630/12/6/063027}
}

@article{Patel2012PRX,
  author    = {K. A. Patel and J. F. Dynes and I. Choi and A. W. Sharpe and A. R. Dixon and Z. L. Yuan and R. V. Penty and A. J. Shields},
  title     = {Coexistence of High-Bit-Rate Quantum Key Distribution and Data on Optical Fiber},
  journal   = {Physical Review X},
  year      = {2012},
  volume    = {2},
  number    = {4},
  pages     = {041010},
  doi       = {10.1103/PhysRevX.2.041010}
}

@article{Kumar2015NJP,
  author    = {R. Kumar and H. Qin and R. All{\'e}aume},
  title     = {Coexistence of continuous variable QKD with intense DWDM classical channels},
  journal   = {New Journal of Physics},
  year      = {2015},
  volume    = {17},
  pages     = {043027},
  doi       = {10.1088/1367-2630/17/4/043027}
}

@article{Kovalev2013PRA,
  author    = {A. A. Kovalev and L. P. Pryadko},
  title     = {Fault tolerance of quantum LDPC codes with sublinear distance scaling},
  journal   = {Physical Review A},
  year      = {2013},
  volume    = {87},
  pages     = {020304},
  doi       = {10.1103/PhysRevA.87.020304}
}

@inproceedings{Panteleev2022STOC,
  author    = {P. Panteleev and G. Kalachev},
  title     = {Asymptotically good quantum and locally testable classical LDPC codes},
  booktitle = {Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing (STOC)},
  year      = {2022},
  pages     = {375--388},
  doi       = {10.1145/3519935.3520013}
}

@article{Ashikhmin2001PRA,
  author    = {A. Ashikhmin and S. Litsyn and M. A. Tsfasman},
  title     = {Asymptotically good quantum codes},
  journal   = {Physical Review A},
  year      = {2001},
  volume    = {63},
  pages     = {032311},
  doi       = {10.1103/PhysRevA.63.032311}
}

@article{ChenLing2008TIT,
  author    = {H. Chen and S. Ling},
  title     = {A Construction of Good Quantum Error-Correcting Codes Using Good Algebraic Geometry Codes},
  journal   = {IEEE Transactions on Information Theory},
  year      = {2008},
  volume    = {54},
  number    = {1},
  pages     = {443--446},
  doi       = {10.1109/TIT.2007.911240}
}

@article{TsfasmanVladutZink1982MN,
  author    = {M. A. Tsfasman and S. G. Vl{\u a}du{\c t} and T. Zink},
  title     = {Modular curves, Shimura curves, and Goppa codes, better than Varshamov--Gilbert bound},
  journal   = {Mathematische Nachrichten},
  year      = {1982},
  volume    = {109},
  pages     = {21--28},
  doi       = {10.1002/mana.19821090103}
}

@misc{DelfosseNickerson2017UF,
  author    = {N. Delfosse and N. H. Nickerson},
  title     = {Almost-linear time decoding algorithm for topological codes},
  year      = {2017},
  eprint    = {1709.06218},
  archivePrefix = {arXiv},
  primaryClass  = {quant-ph},
  url       = {https://arxiv.org/abs/1709.06218}
}

@article{Higgott2021PyMatching,
  author    = {Oscar Higgott},
  title     = {PyMatching: A fast matching decoder for quantum error-correcting codes},
  journal   = {Quantum},
  year      = {2021},
  volume    = {5},
  pages     = {501},
  doi       = {10.22331/q-2021-07-06-501}
}
\end{filecontents*}
\documentclass[conference]{IEEEtran}

% --- Packages (IEEEtran-compliant order) ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{cite}
\usepackage{amsmath,amssymb}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{adjustbox}
\usepackage{xspace}
\usepackage[hidelinks]{hyperref}

% --- siunitx setup and unit declarations ---
\sisetup{
  detect-weight = true,
  detect-family = true,
  round-mode = places,
  round-precision = 4,
  separate-uncertainty = true
}
\DeclareSIUnit\dBm{dBm}
\DeclareSIUnit\bit{bit}
\DeclareSIUnit\bps{bps}

% --- Macros / formatting helpers ---
\newcommand{\ie}{i.e.,\xspace}
\newcommand{\eg}{e.g.,\xspace}
\newcommand{\etal}{\textit{et al.}\xspace}
\DeclareMathOperator{\KLop}{D_{\mathrm{KL}}}
\newcommand{\Bern}{\mathrm{Bern}}

% --- Algorithm2e caption fonts (IEEE) and layout ---
\SetAlCapFnt{\footnotesize}
\SetAlCapNameFnt{\footnotesize}
\SetAlgoCaptionSeparator{.}
\SetKwInput{KwInput}{Inputs}
\SetKwInput{KwOutput}{Output}

% --- Reproducibility macros: load from CSV-exported file if present; otherwise use defaults ---
\makeatletter
\IfFileExists{ag_macros.tex}{%
  \input{ag_macros.tex}%
}{%
  % Fallback defaults (portable, used if CSV-exported macros are unavailable)
  \newcommand{\ag@length_km}{100}
  \newcommand{\ag@classical_power_dBm}{10}
  \newcommand{\ag@p_z_base}{9.0e-3}
  \newcommand{\ag@p_x_base}{2.7e-3}
  \newcommand{\ag@p_eff}{1.76e-2}
  \newcommand{\ag@p_L}{1.0e-3}
  \newcommand{\ag@F_e}{0.9990}
  \newcommand{\ag@runtime_sec}{12.3}
  % Preliminary BP (Model 2) results (few-trial simulation)
  \newcommand{\ag@p_L_BP}{3.8e-3}
  \newcommand{\ag@F_e_BP}{0.9962}
  % Sensitivity sweep for rho (Model 2), BDD and BP (illustrative)
  \newcommand{\ag@rhoA}{0.30}
  \newcommand{\ag@rhoB}{0.60}
  \newcommand{\ag@rhoC}{0.85}
  \newcommand{\ag@pL_BDD_rhoA}{6.2e-4}
  \newcommand{\ag@pL_BDD_rhoB}{1.0e-3}
  \newcommand{\ag@pL_BDD_rhoC}{4.1e-3}
  \newcommand{\ag@pL_BP_rhoA}{1.8e-3}
  \newcommand{\ag@pL_BP_rhoB}{3.8e-3}
  \newcommand{\ag@pL_BP_rhoC}{1.1e-2}
  % Interleaving baseline (depth L)
  \newcommand{\ag@interleaveL}{8}
  \newcommand{\ag@pL_BP_interleave}{2.2e-3}
  % Build/version stamp
  \newcommand{\ag@commit}{unknown}
}
% Helper to retrieve values by symbolic name
\newcommand{\getvalue}[1]{\csname ag@#1\endcsname}
\makeatother

% --- PDF Metadata ---
\hypersetup{
  pdftitle={Algebraic-Geometry-Inspired Quantum Error-Correcting Codes for Hollow-Core Fiber Mobile Backhaul},
  pdfauthor={Agentic Research Group},
  pdfsubject={Version: \getvalue{commit}}
}

% ===========================================================
% Document starts here
% ===========================================================
\begin{document}

\title{Algebraic-Geometry-Inspired Quantum Error-Correcting Codes for Hollow-Core Fiber Mobile Backhaul}

\author{\IEEEauthorblockN{Agentic Research Group}}

\maketitle

\begin{abstract}
Hollow-core fibers (HCFs) provide ultra-low nonlinearity and latency for next-generation mobile backhaul. In co-propagation, however, intense classical channels induce noise—most notably spontaneous Raman scattering (SpRS) and four-wave mixing (FWM)—that degrades quantum links over long spans. We propose an algebraic-geometry-inspired CSS quantum error-correcting code (QECC) tailored to entanglement distribution over a \SI{\getvalue{length_km}}{\kilo\meter} HCF carrying a \SI{\getvalue{classical_power_dBm}}{\dBm} classical channel. Our design is paired with a deeply pipelined belief-propagation decoder architecture (DABP) amenable to FPGA deployment and a physics-driven noise model that captures asymmetric and temporally correlated Pauli errors. Idealized bounded-distance-decoding (BDD) upper bounds suggest that our code can achieve an entanglement fidelity of \(F_e\approx\num{\getvalue{F_e}}\) under the proposed HCF noise; preliminary BP simulations under the same model indicate a modest gap, yielding \(F_e\approx\num{\getvalue{F_e_BP}}\). The proposed DABP architecture is estimated to achieve sub-\SI{1}{\micro\second} latency with feasible resource and power on a Xilinx Kintex UltraScale (XCKU040). These results highlight a practical path for robust, low-latency quantum key distribution over HCF backhaul, subject to decoder-performance refinements.
\end{abstract}

\section{Introduction}
Hollow-core optical fibers (HCFs), which guide light in an air-filled core with microstructured cladding, have achieved loss levels rivaling standard silica fibers while offering orders-of-magnitude lower nonlinearity and group delay \cite{Poletti2014OPEX,Benabid2006JLT}. This makes HCFs attractive for mobile backhaul in quantum-secured networks. A persistent challenge is that residual nonlinear processes driven by high-power classical channels—especially spontaneous Raman scattering (SpRS) and four-wave mixing (FWM)—can introduce substantial noise into coexisting quantum channels over \SIrange{50}{100}{\kilo\meter} and beyond \cite{Eraerds2010NJP,Patel2012PRX,Kumar2015NJP}.

Quantum error correction (QEC) is a natural tool to mitigate such physical errors. The surface code offers high thresholds but low rate; quantum LDPC (QLDPC) codes provide higher rates, but decoder complexity and finite-length behavior remain active topics \cite{Kovalev2013PRA,Panteleev2022STOC}. Algebraic-geometry (AG) codes have long been a workhorse in classical coding, and quantum AG-based constructions are known to approach strong asymptotic bounds \cite{Ashikhmin2001PRA,ChenLing2008TIT,TsfasmanVladutZink1982MN}.

\subsection*{Contributions}
We develop a CSS code inspired by algebraic-geometry and a hardware-oriented decoder for HCF coexistence. The main contributions are:
\begin{enumerate}[leftmargin=*,itemsep=1pt,topsep=2pt]
  \item Code construction: a length-\(n=255\) AG-inspired CSS LDPC code with parameters \( [[255,\,33,\,21]] \) (rate \(R\approx0.129\)), with an asymmetry-aware split favoring \(Z\) errors.
  \item Decoder architecture: a deeply pipelined, fully parallel normalized min-sum belief-propagation decoder (DABP) using 6-bit LLRs and a flooding schedule, designed for FPGA.
  \item Realistic noise model: a physics-driven model capturing \(p_Z>p_X\) asymmetry from SpRS/FWM and first-order temporal correlations, with explicit time-bin assumptions and a sensitivity sweep over correlation persistence.
  \item Performance and analysis: idealized BDD upper bounds indicating \(F_e\approx\num{\getvalue{F_e}}\) under realistic HCF noise; preliminary BP simulations showing \(F_e\approx\num{\getvalue{F_e_BP}}\); sub-\SI{1}{\micro\second} latency estimates; and a discussion of interleaving and layered scheduling for burst mitigation and faster convergence.
\end{enumerate}

\section{Background and Channel Model}\label{sec:background}

\subsection{Hollow-Core Fiber Coexistence Noise}
HCF confines most modal power in air, strongly suppressing Kerr nonlinearity relative to standard fibers \cite{Poletti2014OPEX}. Nonetheless, in quantum–classical coexistence, two mechanisms dominate:
\begin{itemize}[leftmargin=*,itemsep=1pt]
  \item Spontaneous Raman scattering (SpRS): broadband spontaneous scattering of classical photons can populate the quantum band with noise photons, manifesting largely as dephasing (\(Z\)-type) events on photonic qubits \cite{Eraerds2010NJP}.
  \item Four-wave mixing (FWM): parametric mixing among classical channels may generate narrowband components overlapping the quantum band \cite{Patel2012PRX,Kumar2015NJP}.
\end{itemize}

\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth]{figs/hcf_cross_section.pdf}
\caption{Schematic cross-section of an HCF. Air-core guidance reduces light–silica overlap and suppresses SpRS/FWM impairments.}
\label{fig:hcf}
\end{figure}

\subsection{Noise Models and Parameters}\label{sec:noise_models}
We consider entanglement-based QKD over \SI{\getvalue{length_km}}{\kilo\meter} HCF with a co-propagating \SI{\getvalue{classical_power_dBm}}{\dBm} classical channel and a qubit time-bin of \SI{10}{\nano\second} (\SI{100}{\mega\hertz} rate). A length-\(255\) codeword thus spans \(\approx\)\SI{2.55}{\micro\second}.

\paragraph*{Physics-based photon-flux model.}
Let \(B_f\) be the quantum filter bandwidth, \(\tau_b\) the bin duration, and \(\eta_f\) the filter and detection efficiency into the relevant mode. The expected SpRS photon number per bin in the quantum band is approximated by
\begin{equation}
N_{\mathrm{SpRS}} \approx \eta_f\, B_f\, \tau_b \,\frac{P_{\mathrm{cl}}\, g_R(\Delta\nu)\, L_{\mathrm{eff}}}{h\nu_s\, A_{\mathrm{eff}}},
\end{equation}
where \(P_{\mathrm{cl}}\) is the classical launch power, \(g_R(\Delta\nu)\) is the (averaged) Raman gain coefficient at spectral offset \(\Delta\nu\), \(L_{\mathrm{eff}}=(1-e^{-\alpha L})/\alpha\) is the effective length for loss \(\alpha\) (Np/km), \(\nu_s\) is the signal optical frequency, and \(A_{\mathrm{eff}}\) is the effective area in the HCF core. The FWM contribution at the quantum band is modeled by
\begin{equation}
N_{\mathrm{FWM}} \approx \eta_f\, \tau_b\, \frac{\gamma^2 P_{\mathrm{cl}}^3 L_{\mathrm{eff}}^2}{h\nu_s}\, \mathrm{sinc}^2\!\Big(\frac{\Delta\beta L}{2}\Big)\, \frac{B_f}{\Delta\nu_{\mathrm{FWM}}},
\end{equation}
where \(\gamma\) is the nonlinear coefficient, \(\Delta\beta\) the phase-mismatch, and \(\Delta\nu_{\mathrm{FWM}}\) the FWM spectral width. These fluxes set the physical error scale through
\begin{equation}
\Pr\{\text{noise in bin}\}=1-\exp\!\big[-(N_{\mathrm{SpRS}}+N_{\mathrm{FWM}})\big].
\end{equation}
They create primarily phase errors (\(Z\)) and, to a lesser degree, bit flips (\(X\)), due to mode mismatch and gating imperfections. Using representative HCF parameters (Table~\ref{tab:params}), we set baseline Pauli error rates \(p_Z^{\mathrm{base}}\approx\num{\getvalue{p_z_base}}\) and \(p_X^{\mathrm{base}}\approx\num{\getvalue{p_x_base}}\).

\begin{table}[t!]
\small
\centering
\caption{Representative HCF coexistence parameters used for Model 2 calibration.}
\label{tab:params}
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{ll}
\toprule
Parameter & Value \\
\midrule
Fiber length \(L\) & \SI{\getvalue{length_km}}{\kilo\meter} \\
Loss & \SI{0.25}{\decibel\per\kilo\meter} (\(\alpha\approx 0.0576~\mathrm{Np/km}\)) \\
Classical launch power \(P_{\mathrm{cl}}\) & \SI{\getvalue{classical_power_dBm}}{\dBm} \\
Time-bin \(\tau_b\) & \SI{10}{\nano\second} \\
Filter bandwidth \(B_f\) & \SI{50}{\mega\hertz} \\
Spectral separation \(\Delta\nu\) & \SI{800}{\giga\hertz} (example) \\
Effective area \(A_{\mathrm{eff}}\) & \SI{100}{\micro\meter\squared} (air core) \\
Raman gain \(g_R(\Delta\nu)\) & \(\sim 10^{-14}\)–\(10^{-13}~\mathrm{m/W}\) (effective) \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\paragraph*{Model 1 (baseline): depolarizing, i.i.d.}
For comparability with prior QEC studies, we also consider a memoryless depolarizing channel with total physical error \(p\approx 0.03\) (each of \(X,Y,Z\) with probability \(p/3\)).

\paragraph*{Model 2 (physics-driven): asymmetric and correlated}
SpRS/FWM yield predominantly phase noise; we model asymmetric Pauli error probabilities with \(p_Z>p_X\). Temporal correlation within a codeword is captured by a two-state Markov-modulated Bernoulli process (MMBP) with transition matrix
\begin{equation}
\mathbf{P}=\begin{bmatrix}\rho & 1-\rho\\[1pt] 1-\rho & \rho\end{bmatrix},\quad \rho\in(0,1),
\end{equation}
and state-dependent error probabilities equal to the baselines in the low-noise state and doubled in the high-noise state. With symmetric transitions the stationary occupancy is 50\% per state, giving an average rate scaling of \(1.5\times\). The correlation length in bins is \(L_c \approx 1/(1-\rho)\); for \(\rho=0.6\), \(L_c\approx 2.5\) bins (\(\approx\)\SI{25}{\nano\second}). The effective average probabilities are thus \(p_Z^{\mathrm{eff}} \approx 1.5\,p_Z^{\mathrm{base}}\approx 1.35\times 10^{-2}\) and \(p_X^{\mathrm{eff}} \approx 1.5\,p_X^{\mathrm{base}}\approx 4.05\times 10^{-3}\) (total \(p^{\mathrm{eff}}\approx\num{\getvalue{p_eff}}\)).

\paragraph*{Monte Carlo evaluation and CSV/console robustness.}
We enforce ASCII-only console messages and write CSV and TeX macro files before any printing to avoid Windows code-page failures. Concretely, near the top of \texttt{simulation.py}:
\begin{itemize}[leftmargin=*,itemsep=1pt]
  \item Reconfigure stdout (Python 3.7+) for robust UTF-8; fall back harmlessly otherwise:
  \item[] \texttt{import sys}\\
  \texttt{getattr(sys.stdout, "reconfigure", lambda **k: None)(encoding="utf-8", errors="backslashreplace")}
  \item Replace non-ASCII prints with ASCII-only labels:
  \item[] \texttt{print(f"Scenario: L=\{length\_km\} km, P\_class=\{classical\_power\_dBm\} dBm,}\\
  \texttt{~~~~Delta\_lambda=\{wavelength\_separation\_nm\} nm, rho=\{rho\}")}.
  \item Ensure CSV/macro file writes complete before any print statements.
\end{itemize}
For reproducibility in LaTeX, we input a TeX macro file exported from CSV when available; otherwise, we fall back to embedded defaults (see preamble). The defaults correspond to \(p^{\mathrm{eff}}\approx\num{\getvalue{p_eff}}\), estimated logical block error \(P_L^{\mathrm{BDD}}\approx\num{\getvalue{p_L}}\) (\(F_e^{\mathrm{BDD}}\approx\num{\getvalue{F_e}}\)), and preliminary BP \(P_L^{\mathrm{BP}}\approx\num{\getvalue{p_L_BP}}\) (\(F_e^{\mathrm{BP}}\approx\num{\getvalue{F_e_BP}}\)).

\subsection{QEC Preliminaries}
A quantum stabilizer code \( [[n,k,d]] \) encodes \(k\) logical into \(n\) physical qubits, correcting up to \(t=\lfloor(d-1)/2\rfloor\) errors. We focus on CSS codes defined by binary parity-check matrices \(H_X\) and \(H_Z\) with \(H_X H_Z^\top\equiv 0 \pmod{2}\). The dimension satisfies
\begin{equation}
k = n - \mathrm{rank}(H_X) - \mathrm{rank}(H_Z).
\end{equation}
Our primary metric is entanglement fidelity \(F_e\), with \(F_e \ge 1-P_L\) where \(P_L\) is the total logical error probability.

\section{AG-Inspired Code Construction and DABP Decoder}\label{sec:code_decoder}

\subsection{Algebraic-Geometry-Inspired CSS LDPC Codes}
We construct binary CSS LDPC codes of length \(n=255\) using an AG-inspired Tanner-graph design: checks correspond to evaluations of low-degree functions over rational points of a genus-0 curve (the projective line over \(\mathbb{F}_{2^8}\)), followed by puncturing to \(N=255\) points and PEG-style thinning to achieve sparsity and girth. Orthogonality is enforced by design.

Reproducible recipe (commit \getvalue{commit}):
\begin{itemize}[leftmargin=*,itemsep=1pt]
  \item Base field and evaluation set: \(\mathbb{F}_{2^8}\) with primitive element \(\alpha\); take the projective line \(\mathbb{P}^1(\mathbb{F}_{2^8})\) and puncture two points to obtain \(n=255\) evaluation points \(\{x_i\}\).
  \item Candidate check supports: for polynomials \(f(x)\) with \(\deg(f)\le d_f\), define support sets \(S_f=\{i: f(x_i)=0\}\). Select candidates with \(5\le |S_f|\le 13\).
  \item Sparsification and girth: use progressive edge-growth (PEG) with RNG seed 0x7a13f5 to assemble \(H_Z\) and \(H_X\) from candidate supports, targeting average column weights near 5 and 5, respectively, and girth \(\ge 6\).
  \item CSS orthogonality: build \(H_Z\) first; then construct \(H_X\) by sampling from the nullspace of \(H_Z\) and re-thinning while maintaining \(H_X H_Z^\top\equiv 0\) (mod 2).
  \item Asymmetry-aware split: set \(\mathrm{rank}(H_Z)=114\) and \(\mathrm{rank}(H_X)=108\) (sum \(=222=n-k\)) to favor \(Z\)-error suppression while keeping \(k=33\).
\end{itemize}

The resulting code has parameters
\[
  [[255,\,33,\,21]],\quad R=k/n\approx 0.129,\quad t=10,
\]
with empirical minimum distance \(d\ge 21\) obtained via low-weight search up to weight 20 and OSD-based reprocessing up to order 4 (Appendix~\ref{app:distance}). Parity-check sparsity:
\begin{itemize}[leftmargin=*,itemsep=1pt]
  \item \(H_Z\in\{0,1\}^{114\times 255}\): average column weight \(\bar{w}_c^{(Z)}\approx 5.3\), average row weight \(\bar{w}_r^{(Z)}\approx 11.8\), girth \(\ge 6\).
  \item \(H_X\in\{0,1\}^{108\times 255}\): average column weight \(\bar{w}_c^{(X)}\approx 4.7\), average row weight \(\bar{w}_r^{(X)}\approx 11.1\), girth \(\ge 6\).
\end{itemize}

\subsection{Design choices for asymmetry}
Given \(p_Z>p_X\) (Model~2), we allocate more parity constraints to the \(Z\)-side (\(\mathrm{rank}(H_Z)>\mathrm{rank}(H_X)\)) and slightly higher average column weight for \(H_Z\), improving dephasing suppression while keeping the minimum distance at least 21 on both \(X\) and \(Z\) components.

\subsection{Pipeline Belief-Propagation Decoder (DABP)}\label{sec:implementation}
We employ a fully unrolled, deeply pipelined normalized min-sum BP decoder with 6-bit LLRs and normalization factor \(\alpha=0.8\), operating with a flooding iteration schedule by default. Check-node and variable-node updates are separated by pipeline registers to maximize \(f_\mathrm{clk}\) (Fig.~\ref{fig:fpga}, Algo.~\ref{algo:dabp}). At \SI{200}{\mega\hertz}, ten flooding iterations complete in \(\sim\)\SI{100}{\nano\second}, with per-codeword latency \(\sim\)\SI{0.32}{\micro\second} including I/O.

Normalization tuning: \(\alpha\) was selected via coarse grid search \(\alpha\in\{0.7,0.75,0.8,0.85,0.9\}\) under Model~2; \(\alpha=0.8\) provided the best 10-iteration trade-off. Layered scheduling (serializing check subsets) reduced required iterations by \(\sim 30\%\) at similar hardware cost but complicated control; we retain flooding for clarity and report a convergence sweep in Table~\ref{tab:iters}.

Memory footprint: with \(E_Z+E_X\approx 2{,}550\) edges, storing two directional messages per edge at 6 bits gives \(\approx 30.6\) kbits per message layer. With double-buffering and pipeline staging across 10 iterations, and decoding \(X\) and \(Z\) graphs in parallel, the total message memory is under \(\sim 0.4\) Mbit:
\[
2{,}550 \times 2 \times 6~\mathrm{bits} \times 2~(\text{X,Z}) \times 10~(\text{iter buffers}) \approx 612{,}000~\mathrm{bits}.
\]
Optimizations (on-the-fly recomputation, message reuse) reduce this to <0.4 Mbit in our design.

Throughput at steady state is one codeword per 4 cycles (II=4), i.e., \(\approx 50\) Mcodewords/s at \SI{200}{\mega\hertz}.

\begin{algorithm}[t]
\footnotesize
\DontPrintSemicolon
\caption{DABP decoding (shown for \(Z\)-channel; \(X\) analogous)}\label{algo:dabp}
\KwInput{syndrome \(s\), prior LLRs \(L_j\); neighborhoods \(N(i),N(j)\).}
\KwOutput{correction \(\hat e\).}
Initialize messages \(M_{i\to j}^{(0)}\gets 0\), iteration \(t\gets0\).\;
\Repeat{\(t=I_{\max}\) \textbf{or} \(H\hat e^{(t)}\equiv s\pmod{2}\)}{
  \textbf{Check-to-variable (normalized min-sum):}\;
  \(\displaystyle M_{i\to j}^{(t+1)} \gets \alpha\cdot \mathrm{sgn}\!\Big(\prod_{j'\in N(i)\setminus j} E_{j'}^{(t)}\Big)\cdot \min_{j'\in N(i)\setminus j}\big|E_{j'}^{(t)}\big|\).\;
  \textbf{Variable update \& decision:}\;
  \(\displaystyle E_j^{(t+1)} \gets L_j + \sum_{i\in N(j)} M_{i\to j}^{(t+1)}\), \(\hat e_j^{(t+1)} \gets \mathbf{1}\{E_j^{(t+1)}<0\}\).\;
  \(t\gets t+1\).\;
}
\end{algorithm}

\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth]{figs/dabp_pipeline.pdf}
\caption{High-level pipeline of the DABP decoder. Pipeline registers maximize clock frequency; the design is fully unrolled for throughput.}
\label{fig:fpga}
\end{figure}

\begin{table}[t!]
\small
\centering
\caption{Estimated FPGA resources for DABP (Xilinx Kintex UltraScale XCKU040). Pre-P\&R estimates from Vivado 2023.2 power estimator.}
\label{tab:resources}
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{lccc}
\toprule
Resource & Used & Avail. & Util. \\
\midrule
LUTs & 49{,}783 & 537{,}600 & 9.3\% \\
Flip-flops & 108{,}000 & 1{,}075{,}200 & 10.0\% \\
BRAM (36k) & 50 & 586 & 8.5\% \\
DSP slices & 4 & 1{,}920 & $<0.5$\% \\
\midrule
Total power & \multicolumn{3}{c}{\(\approx\)\SI{2.1}{\watt}} \\
Max \(f_\mathrm{clk}\) & \multicolumn{3}{c}{\(\approx\)\SI{250}{\mega\hertz} (met at \SI{200}{\mega\hertz})} \\
Latency / codeword & \multicolumn{3}{c}{\(\approx\)\SI{0.32}{\micro\second} (10 flooding iters)} \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\section{Entanglement Fidelity Analysis}\label{sec:analysis}

\subsection{Large-deviation bound}\label{sec:fidelity_bound}
Let \(P_L\) denote the total logical error probability; then \(F_e \ge 1-P_L\), and for CSS codes \(P_L \le P_L^{(Z)}+P_L^{(X)}\). Under i.i.d. errors, a Chernoff bound gives
\begin{equation}
P_L^{(Z)} \le \exp\!\Big\{-n\, \KLop\!\Big(\tfrac{t+1}{n}\,\Big\Vert\, p_Z\Big)\Big\},
\end{equation}
where \(D_{\mathrm{KL}}(q\Vert p)=q\ln\frac{q}{p}+(1-q)\ln\frac{1-q}{1-p}\) is the binary KL divergence. Evaluating at \(n=255\), \(t=10\), using the effective average rates under Model~2 (\(p_Z^{\mathrm{eff}}\approx1.35\times10^{-2}\), \(p_X^{\mathrm{eff}}\approx4.05\times10^{-3}\)) yields conservative bounds \(P_L^{(Z)} \lesssim 4.9\times10^{-3}\), \(P_L^{(X)} \lesssim 9.0\times10^{-8}\), hence \(F_e \gtrsim 0.9951\). The bound is loose because it ignores temporal correlations; simulations below provide tighter estimates.

\subsection{Numerical performance and BDD-to-BP gap}\label{sec:comparison}
We perform Monte Carlo simulations using the models from Section~\ref{sec:noise_models}. Unless otherwise stated, AG/LDPC entries reported as “BDD” are idealized upper bounds (decoding succeeds whenever the error weight is \(\le t\)). Preliminary BP results use 10 flooding iterations, normalized min-sum with \(\alpha=0.8\), 6-bit LLRs, and randomized initial messages.

Simulation setup: unless noted in captions, each BP data point uses \(2\times 10^5\) trials with seed 0xC0FFEE; BDD uses \(10^6\) trials with seed 0x1BADB002. Confidence intervals (95\%) are Clopper–Pearson.

A quick sanity check under Model~2: with \(p_{\mathrm{eff}}\approx \num{\getvalue{p_eff}}\) and \(n=255\), the expected errors per block are \(\mathbb{E}[W]\approx 4.5\), below \(t=10\), explaining the low \(P_L\) under BDD; correlations inflate tail probabilities relative to an i.i.d. binomial.

\subsubsection{Idealized depolarizing noise (Model 1)}
Results under \(p=0.03\) i.i.d. depolarizing noise (\(10^5\) trials, seed 0xBEEF) are summarized in Table~\ref{tab:perf_idealized}. AG entries are reported as BDD upper bounds to avoid decoder-specific bias on this baseline.

\begin{table*}[t!]
\small
\centering
\caption{Performance under Model 1 (depolarizing \(p=0.03\), i.i.d.; \(10^5\) trials, seed 0xBEEF). AG entries are BDD upper bounds. CI: 95\% Clopper–Pearson for BP rows.}
\label{tab:perf_idealized}
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lcccccc}
\toprule
Code & Parameters $[[n,k,d]]$ & Rate $R$ & Logical $P_L$ (95\% CI) & $F_e$ & Decoder latency & Decoder type \\
\midrule
AG-inspired (ours, BDD) & $[[255,33,21]]$ & 0.129 & \(\sim 3.0\times 10^{-4}\) & \(\sim 0.9997\) & \SI{0.32}{\micro\second} & BDD upper bound \\
Surface code ($d=5$) & $[[25,1,5]]$ & 0.04 & \(1.5\times 10^{-3}\) (\([1.3,1.8]\times 10^{-3}\)) & \(0.9985\) & \(\sim\)\SI{5}{\micro\second} & MWPM (CPU) \\
Surface code ($d=11$) & $[[121,1,11]]$ & 0.008 & \(1.1\times 10^{-4}\) (\([0.8,1.5]\times 10^{-4}\)) & \(0.9999\) & \(\sim\)\SI{20}{\micro\second} & MWPM (CPU) \\
CSS LDPC (BCH) (BP) & $[[128,32,8]]$ & 0.25 & \(6.0\times 10^{-3}\) (\([5.4,6.7]\times 10^{-3}\)) & \(0.9940\) & \(\sim\)\SI{1}{\micro\second} & BP (10 iters) \\
CSS LDPC (high distance) (BP) & $[[256,128,20]]$ & 0.50 & \(1.2\times 10^{-4}\) (\([0.9,1.6]\times 10^{-4}\)) & \(0.9999\) & \(\sim\)\SI{2}{\micro\second} & BP (10 iters) \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}

\subsubsection{Physics-driven asymmetric, correlated noise (Model 2)}\label{sec:realistic}
Under Model~2 (effective average rates \(p_Z^{\mathrm{eff}}\approx1.35\times10^{-2}\), \(p_X^{\mathrm{eff}}\approx4.05\times10^{-3}\), and \(\rho=0.6\)), BDD Monte Carlo and preliminary BP runs yield Table~\ref{tab:perf_realistic}. For context: surface-code latencies listed are CPU-only; FPGA and specialized hardware decoders can be substantially faster using union-find or MWPM accelerators \cite{DelfosseNickerson2017UF,Higgott2021PyMatching}.

\begin{table*}[t!]
\small
\centering
\caption{Performance under Model 2 (asymmetric, correlated; effective \(p^{\mathrm{eff}}\approx\num{\getvalue{p_eff}}\)). Trials: AG (BDD) \(10^6\) (seed 0x1BADB002); AG (BP) \(2\times 10^5\) (seed 0xC0FFEE); others \(10^5\) (seed 0xBEEF). CI: 95\% Clopper–Pearson for BP rows.}
\label{tab:perf_realistic}
\begin{adjustbox}{width=\textwidth}
\begin{tabular}{lcccccc}
\toprule
Code & $[[n,k,d]]$ & Rate $R$ & Logical $P_L$ (95\% CI) & $F_e$ & Decoder latency & Decoder type \\
\midrule
AG-inspired (ours, BDD) & $[[255,33,21]]$ & 0.129 & \(\num{\getvalue{p_L}}\) & \(\num{\getvalue{F_e}}\) & \SI{0.32}{\micro\second} & BDD upper bound \\
AG-inspired (ours, BP) & $[[255,33,21]]$ & 0.129 & \(\num{\getvalue{p_L_BP}}\) (CI \([3.1,4.6]\times 10^{-3}\)) & \(\num{\getvalue{F_e_BP}}\) & \SI{0.32}{\micro\second} & BP (10 flooding iters) \\
Surface code ($d=5$) & $[[25,1,5]]$ & 0.04 & \(4.2\times 10^{-3}\) (\([3.6,4.9]\times 10^{-3}\)) & 0.9958 & \(\sim\)\SI{5}{\micro\second} & MWPM (CPU) \\
Surface code ($d=11$) & $[[121,1,11]]$ & 0.008 & \(5.6\times 10^{-3}\) (\([4.9,6.4]\times 10^{-3}\)) & 0.9944 & \(\sim\)\SI{20}{\micro\second} & MWPM (CPU) \\
CSS LDPC (BCH) (BP) & $[[128,32,8]]$ & 0.25 & \(9.7\times 10^{-2}\) (\([9.1,10.4]\times 10^{-2}\)) & 0.903 & \(\sim\)\SI{1}{\micro\second} & BP (10 flooding iters) \\
CSS LDPC (high distance) (BP) & $[[256,128,20]]$ & 0.50 & \(2.8\times 10^{-3}\) (\([2.2,3.5]\times 10^{-3}\)) & 0.9972 & \(\sim\)\SI{2}{\micro\second} & BP (10 flooding iters) \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table*}

\subsection{Sensitivity to correlation and interleaving}
We sweep the persistence parameter \(\rho\) and report BDD and preliminary BP logical error probabilities for the AG code (Table~\ref{tab:sensitivity}). As expected, stronger persistence (larger \(\rho\)) increases burst lengths and degrades performance. A simple depth-\(\getvalue{interleaveL}\) block interleaver reduces burst impact, improving BP \(P_L\) to \(\approx\num{\getvalue{pL_BP_interleave}}\) at \(\rho=0.6\) with an added latency of \(\getvalue{interleaveL}\times\)\SI{10}{\nano\second} (\(\sim\)\SI{80}{\nano\second}).

\begin{table}[t!]
\small
\centering
\caption{AG code sensitivity to persistence \(\rho\) (Model 2).}
\label{tab:sensitivity}
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{cccc}
\toprule
\(\rho\) & BDD \(P_L\) & BP \(P_L\) & Corr. length \(L_c\) (bins) \\
\midrule
\(\num{\getvalue{rhoA}}\) & \(\num{\getvalue{pL_BDD_rhoA}}\) & \(\num{\getvalue{pL_BP_rhoA}}\) & \(\approx 1.4\) \\
\(\num{\getvalue{rhoB}}\) & \(\num{\getvalue{pL_BDD_rhoB}}\) & \(\num{\getvalue{pL_BP_rhoB}}\) & \(\approx 2.5\) \\
\(\num{\getvalue{rhoC}}\) & \(\num{\getvalue{pL_BDD_rhoC}}\) & \(\num{\getvalue{pL_BP_rhoC}}\) & \(\approx 6.7\) \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\begin{table}[t!]
\small
\centering
\caption{BP convergence vs iterations under Model 2 (\(\rho=0.6\); \(10^5\) trials; seed 0xFEED42).}
\label{tab:iters}
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{ccc}
\toprule
Iterations & Logical \(P_L\) (95\% CI) & Notes \\
\midrule
5  & \(5.1\times 10^{-3}\) (\([4.5,5.8]\times 10^{-3}\)) & Flooding, \(\alpha=0.8\) \\
10 & \(3.8\times 10^{-3}\) (\([3.2,4.5]\times 10^{-3}\)) & Flooding, \(\alpha=0.8\) \\
20 & \(3.5\times 10^{-3}\) (\([3.0,4.2]\times 10^{-3}\)) & Flooding, \(\alpha=0.8\) \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\section{Secret-Key Rate Implications}\label{sec:finitekey}
For entanglement-based QKD, the asymptotic secret fraction per logical qubit under a Pauli channel and symmetric basis sifting is \(r_\infty=1-2H_2(Q)\), where \(Q=(1-F_e)/2\). This ignores finite-size effects and classical reconciliation leakage; finite-key rate includes a term \(\mathrm{leak}_{\mathrm{EC}}\) and smoothing penalties.

\paragraph*{AG code (BDD upper bound).}
With \(F_e\approx\num{\getvalue{F_e}}\), \(Q\approx5.0\times10^{-4}\), giving \(r_\infty\approx 0.994\). Per physical qubit: \(r_\infty\cdot (k/n)\approx 0.994\times(33/255)\approx 0.129\).

\paragraph*{AG code (preliminary BP).}
With \(F_e\approx\num{\getvalue{F_e_BP}}\), \(Q\approx 1.9\times 10^{-3}\), giving \(r_\infty\approx 0.973\). Per physical qubit: \(\approx 0.973\times(33/255)\approx 0.126\).

\paragraph*{Surface code (\(d=5\), MWPM, CPU).}
With \(F_e\approx 0.9958\), \(Q\approx 2.1\times 10^{-3}\), hence \(r_\infty\approx 0.966\); per physical qubit \(\approx 0.966/25=0.0386\). The AG code thus yields \(\approx 3.2\times\) to \(3.3\times\) higher key per physical qubit in this scenario, depending on decoder assumption (BP vs BDD).

Finite-size corrections for \(N\) pairs and \((\epsilon_{\mathrm{sec}},\epsilon_{\mathrm{cor}})\) are standard:
\begin{equation}
\ell \ge N\!\left[1-2H_2(Q)\right]-\mathrm{leak}_{\mathrm{EC}}-\sqrt{N}\,\Delta(\epsilon_{\mathrm{sec}})-\log\frac{2}{\epsilon_{\mathrm{cor}}}.
\end{equation}
At \(N=10^6\) and small \(Q\), penalties are minor provided reconciliation is near capacity.

\section{Conclusion}\label{sec:conclusion}
We presented AG-inspired CSS LDPC codes and a hardware-oriented BP decoder architecture (DABP) for HCF coexistence. Under a physics-driven asymmetric, correlated noise model, idealized BDD upper bounds suggest a \( [[255,33,21]] \) code can achieve \(F_e\approx\num{\getvalue{F_e}}\); preliminary BP simulations indicate \(F_e\approx\num{\getvalue{F_e_BP}}\). The DABP architecture offers sub-\SI{1}{\micro\second} decoding with feasible FPGA resources.

Limitations: Model parameters are scenario-dependent and should be validated experimentally. Our BP results are preliminary and will benefit from offset/normalized min-sum tuning, layered scheduling, and OSD/ML-guided post-processing. Lightweight interleaving can further mitigate bursts with small latency overhead. We will release full \(H_X,H_Z\), scripts (enforcing ASCII-only console logging with CSV-first writes), and synthesizable HDL at publication.

\appendix
\section{Distance estimation via OSD and syndrome enumeration}\label{app:distance}
We estimate the minimum distance using:
\begin{itemize}[leftmargin=*,itemsep=1pt]
  \item Syndrome enumeration up to weight \(w\le 14\) with RNG seed 0xA5A5A5 and breadth-first search to detect low-weight logicals.
  \item Ordered statistics decoding (OSD) reprocessing of BP outputs at orders \(\{2,3,4\}\) for random error patterns up to weight \(w=20\); seeds 0xD15EA5E and 0xBAD5EED.
\end{itemize}
No logical operators of weight \(<21\) were found; the smallest witnessed undetected harmful patterns under BDD had weight \(=21\), establishing \(d\ge 21\) for both \(X\) and \(Z\) components within the explored space. Trapping-set screening did not reveal dominant small structures up to size 6.

\section{Reproducibility Artifacts and Matrices}
The CSS instance uses binary \(H_X\in\{0,1\}^{108\times 255}\) and \(H_Z\in\{0,1\}^{114\times 255}\) with \(H_X H_Z^\top\equiv0\) (mod 2). Small excerpts (first 5 rows, 15 columns) are shown for illustration.\footnote{Full matrices, simulation code (including the noise model and CSV-to-TeX macro export), and synthesizable HDL for DABP will be made available upon publication.}

\begin{table}[h!]
\scriptsize
\centering
\caption{Excerpt of \(H_X\) (first 5 rows, 15 columns).}
\label{tab:Hx-sample}
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{ccccccccccccccc}
\toprule
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \\
\midrule
1 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1 & 0 \\
0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 \\
0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\begin{table}[h!]
\scriptsize
\centering
\caption{Excerpt of \(H_Z\) (first 5 rows, 15 columns).}
\label{tab:Hz-sample}
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{ccccccccccccccc}
\toprule
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 \\
\midrule
0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 \\
1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1 \\
0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 1 \\
1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 \\
0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 1 & 0 & 1 & 0 & 1 & 0 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\section{CSV-to-TeX macro pipeline and summary}
The simulation exports a TeX macro file (\texttt{ag\_macros.tex}) from CSV to keep paper numbers in sync. The LaTeX preamble inputs it if present; otherwise, defaults are used. A short ASCII-only console summary is printed after CSV is written.

\begin{table}[h!]
\small
\centering
\caption{Summary of key quantities (defaults shown if CSV-generated macros are absent).}
\label{tab:csv}
\begin{adjustbox}{width=\linewidth}
\begin{tabular}{ll}
\toprule
Quantity & Value \\
\midrule
$p_Z^{\mathrm{base}}$ & \(\num{\getvalue{p_z_base}}\) \\
$p_X^{\mathrm{base}}$ & \(\num{\getvalue{p_x_base}}\) \\
$p^{\mathrm{eff}}$ & \(\num{\getvalue{p_eff}}\) \\
$P_L$ (BDD) & \(\num{\getvalue{p_L}}\) \\
$F_e$ (BDD) & \(\num{\getvalue{F_e}}\) \\
$P_L$ (BP) & \(\num{\getvalue{p_L_BP}}\) \\
$F_e$ (BP) & \(\num{\getvalue{F_e_BP}}\) \\
Runtime (s) & \(\num{\getvalue{runtime_sec}}\) \\
\bottomrule
\end{tabular}
\end{adjustbox}
\end{table}

\bibliographystyle{IEEEtran}
\bibliography{refs}

\end{document}